# Probx

> ℹ️ This project is currently a Proof of Concept (POC).

**Probx** is a modular, proof-of-concept web crawling and link processing pipeline built with Python, Flask, MongoDB, and RabbitMQ. **It is designed to automate the discovery, collection, and analysis of web links for cybersecurity research and threat intelligence.**

---

## Architecture Overview

Probx consists of several services:

- **Searcher**: Web UI for submitting Google search queries. Uses `yagooglesearch` to find URLs, stores results in MongoDB, and pushes new URLs to RabbitMQ.
- **Crawler**: Consumes URLs from RabbitMQ, crawls web pages, extracts links, stores them in MongoDB, and publishes discovered links for further processing.
- **Dispatcher**: Manages routing of crawled links to service-specific queues based on regex rules. Includes a web UI for handler management and triggering backfills.
- **MongoDB**: Stores crawled data, search results, and handler configurations.
- **RabbitMQ**: Message broker for decoupling and distributing tasks.
- **Mongo Express**: Web-based MongoDB admin interface.
- **Mitmproxy (Optional)**: Intercepts and inspects HTTP(S) traffic for analysis and debugging within the pipeline.


All services are containerized and orchestrated via Docker Compose.

---

## Status

> ℹ️ Currently a Proof of Concept (POC).

**Probx** is not production-ready, the architecture and code are subject to change as the project evolves. 

Please note that some of the code was generated by artificial intelligence and may not have been reviewed.

---

## Disclaimer
> **This project is for educational and research purposes only. The author does not take any responsibility for the use or misuse of this code.**